[
["index.html", "The EMU-SDMS Manual Welcome", " The EMU-SDMS Manual Raphael Winkelmann Welcome Welcome to the EMU-SDMS Manual! Disclaimer: This manual is still in the making! It will eventually replace all the vignettes of emuR, wrassp as well as the EMU-webApp’s own documentation. This manual is intended to consolidate all of this information in one easy to find location that can easily be updated as new features are added. "],
["installing-the-emu-sdms.html", "1 Installing the EMU-SDMS 1.1 Version disclaimer 1.2 For developers and people interested in the source code", " 1 Installing the EMU-SDMS R Download the R programming language from https://cran.r-project.org/ Install the R programming language by executing the downloaded file and following the on-screen instructions. emuR Start up R. Enter install.packages(&quot;emuR&quot;) after the &gt; prompt to install the package. (You will only need to repeat this if package updates become available.) As the wrassp package is a dependency of the emuR package, it does not have to be installed separately. EMU-webApp (prerequisite) The only thing needed to use the EMU-webApp is a current HTML5 compatible browser (Chrome/Firefox/Safari/Opera/…). However, as most of the development and testing is done using Chrome we recommend using it, as it is by far the best tested browser. 1.1 Version disclaimer This document describes the following versions of the software components: wrassp Package version: 0.1.6 Git tag name: v0.1.6 (on master branch) emuR Package version: 1.0.0 Git tag name: v1.0.0 (on master branch) EMU-webApp Version: 0.1.12 Git SHA1: 7b044a9f9fe19f2eb6d03ec6ec3f20d5b1d25db2 As the development of the EMU Speech Database Management System is still ongoing, be sure you have the correct documentation to go with the version you are using. 1.2 For developers and people interested in the source code The information on how to install and/or access the source code of the developer version including the possibility of accessing the versions described in this document (via the Git tag names mentioned above) is given below. wrassp Source code is available here: https://github.com/IPS-LMU/wrassp/ Install developer version in R: install.packages(&quot;devtools&quot;); library(&quot;devtools&quot;); install_github(&quot;IPS-LMU/wrassp&quot;) Bug reports: https://github.com/IPS-LMU/wrassp/issues emuR Source code is available here: https://github.com/IPS-LMU/emuR/ Install developer version in R: install.packages(&quot;devtools&quot;); library(&quot;devtools&quot;); install_github(&quot;IPS-LMU/emuR&quot;) Bug reports: https://github.com/IPS-LMU/emuR/issues EMU-webApp Source code is available here: https://github.com/IPS-LMU/EMU-webApp/ Bug reports: https://github.com/IPS-LMU/EMU-webApp/issues "],
["chap-overview.html", "2 An overview of the EMU-SDMS 1 2.1 The evolution of the EMU-SDMS 2.2 EMU-SDMS: System architecture and default workflow 2.3 EMU-SDMS: Is it something for you?", " 2 An overview of the EMU-SDMS 1 The EMU Speech Database Management System (EMU-SDMS) is a collection of software tools which aims to be as close to an all-in-one solution for generating, manipulating, querying, analyzing and managing speech databases as possible. It was developed to fill the void in the landscape of software tools for the speech sciences by providing an integrated system that is centered around the R language and environment for statistical computing and graphics (@r-core-team:2016a). This manual contains the documentation for the three software components wrassp, emuR and the EMU-webApp. In addition, it provides an in-depth description of the emuDB database format which is also considered an integral part of the new system. These four components comprise the EMU-SDMS and benefit the speech sciences and spoken language research by providing an integrated system to answer research questions such as: Given an annotated speech database, is the vowel height of the vowel @ (measured by its correlate, the first formant frequency) influenced by whether it appears in a strong or weak syllable? This manual is targeted at new EMU-SDMS users as well as users familiar with the legacy EMU system. In addition, it is aimed at people who are interested in the technical details such as data structures/formats and implementation strategies, be it for reimplementation purposes or simply for a better understanding of the inner workings of the new system. To accommodate these different target groups, after initially giving an overview of the system, this manual presents a usage tutorial that walks the user through the entire process of answering a research question. This tutorial will start with a set of .wav audio and Praat .TextGrid (@boersma:2011a) annotation files and end with a statistical analysis to address the hypothesis posed by the research question. The following Part ?? of this documentation is separated into six chapters that give an in-depth explanation of the various components that comprise the EMU-SDMS and integral concepts of the new system. These chapters provide a tutorial-like overview by providing multiple examples. To give the reader a synopsis of the main functions and central objects that are provided by EMU-SDMS’s main R package emuR, an overview of these functions is presented in Part ??. Part ?? focuses on the actual implementation of the components and is geared towards people interested in the technical details. Further examples and file format descriptions are available in various appendices. This structure enables the novice EMU-SDMS user to simply skip the technical details and still get an in-depth overview of how to work with the new system and discover what it is capable of. A prerequisite that is presumed throughout this document is the reader’s familiarity with basic terminology in the speech sciences (e.g., familiarity with the international phonetic alphabet (IPA) and how speech is annotated at a coarse and fine grained level). Further, we assume the reader has a grasp of the basic concepts of the R language and environment for statistical computing and graphics. For readers new to R, there are multiple, freely available R tutorials online (e.g., https://en.wikibooks.org/wiki/Statistical_Analysis:_an_Introduction_using_R/R_basics). R also has a set of very detailed manuals and tutorials that come preinstalled with R. To be able to access R’s own “An Introduction to R” introduction, simply type help.start() into the R console and click on the link to the tutorial. 2.1 The evolution of the EMU-SDMS The EMU-SDMS has a number of predecessors that have been continuously developed over a number of years (e.g., @harrington:csl1993a, @cassidy:1996a, @cassidy:sc2001a, @bombien:2006a, @harrington:2010a, @john:2012a). The components presented here are the completely rewritten and newly designed, next incarnation of the EMU system, which we will refer to as the EMU Speech Database Management System (EMU-SDMS). The EMU-SDMS keeps most of the core concepts of the previous system, which we will refer to as the legacy system, in place while improving on things like usability, maintainability, scalability, stability, speed and more. We feel the redesign and reimplementation elevates the system into a modern set of speech and language tools that enables a workflow adapted to the challenges confronting speech scientists and the ever growing size of speech databases. The redesign has enabled us to implement several components of the new EMU-SDMS so that they can be used independently of the EMU-SDMS for tasks such as web-based collaborative annotation efforts and performing speech signal processing in a statistical programming environment. Nevertheless, the main goal of the redesign and reimplementation was to provide a modern set of tools that reduces the complexity of the tool chain needed to answer spoken language research questions down to a few interoperable tools. The tools the EMU-SDMS provides are designed to streamline the process of obtaining usable data, all from within an environment that can also be used to analyze, visualize and statistically evaluate the data. Upon developing the new system, rather than starting completely from scratch it seemed more appropriate to partially reuse the concepts of the legacy system in order to achieve our goals. A major observation at the time was that the R language and environment for statistical computing and graphics (@r-core-team:2016a) was gaining more and more traction for statistical and data visualization purposes in the speech and spoken language research community. However, R was mostly only used towards the end of the data analysis chain where data usually was pre-converted into a comma-separated values or equivalent file format by the user using other tools to calculate, extract and pre-process the data. While designing the new EMU-SDMS, we brought R to the front of the tool chain to the point just beyond data acquisition. This allows the entire data annotation, data extraction and analysis process to be completed in R, while keeping the key user requirements in mind. Due to personal experiences gained by using the legacy system for research puposes and in various undergraduate courses (course material usually based on @harrington:2010a), we learned that the key user requirements were data and database portability, a simple installation process, a simplified/streamlined user experience and cross-platform availability. Supplying all of EMU-SDMS’s core functionality in the form of R packages that do not rely on external software at runtime seemed to meet all of these requirements. As the early incarnations of the legacy EMU system and its predecessors were conceived either at a time that predated the R system or during the infancy of R’s package ecosystem, the legacy system was implemented as a modular yet composite standalone program with a communication and data exchange interface to the R/Splus systems (see @cassidy:sc2001a Section 3 for details). Recent developments in the package ecosystem of R such as the availability of the DBI package (@r-special-interest-group-on-databases-r-sig-db:2016a) and the related packages RSQLite and RPostgreSQL (@wickham:2014a, @conway:2016a), as well as the jsonlite package (@ooms:as2014a) and the httpuv package (@rstudio:2015a), have made R an attractive sole target platform for the EMU-SDMS. These and other packages provide additional functional power that enabled the EMU-SDMS’s core functionality to be implemented in the form of R packages. The availability of certain R packages had a large impact on the architectural design decisions that we made for the new system. R Example shows the simple installation process which we were able to achieve due to the R package infrastructure. Compared to the legacy EMU and other systems, the installation process of the entire system has been reduced to a single R command. Throughout this documentation we will try to highlight how the EMU-SDMS is also able to meet the rest of the above key user requirements. rexample:overview-install # install the entire EMU-SDMS # by installing the emuR package install.packages(&quot;emuR&quot;) It is worth noting that throughout this manual R Example code snippets will be given in the form of R Example ??. These examples represent working R code that allow the reader to follow along in a hands-on manor and give a feel for what it is like working with the new EMU-SDMS. 2.2 EMU-SDMS: System architecture and default workflow As was previously mentioned, the new EMU-SDMS is made up of four main components. The components are the emuDB format; the R packages wrassp and emuR; and the web application, the EMU-webApp, which is EMU-SDMS’s new GUI component. An overview of the EMU-SDMS’s architecture and the components’ relationships within the system is shown in Figure 2.1. In Figure 2.1, the emuR package plays a central role as it is the only component that interacts with all of the other components of the EMU-SDMS. It performs file and DB handling for the files that comprise an emuDB (see Chapter @ref(chap:annot_struct_mod)); it uses the wrassp package for signal processing purposes (see Chapter ??; and it can serve emuDBs to the EMU-webApp (see Chapter ??). Figure 2.1: Schematic architecture of the EMU-SDMS Although the system is made of four main components, the user largely only interacts directly with the EMU-webApp and the emuR package. A summary of the default workflow illustrating theses interactions can be seen below: Load database into current R session (load_emuDB()). Database annotation / visual inspection (serve()). This opens up the EMU-webApp in the system’s default browser. Query database (query()). This is optionally followed by requery_hier() or requery_seq() as necessary (see Chapter ?? for details). Get trackdata (e.g. formant values) for the result of a query (get_trackdata()). Prepare data. Visually inspect data. Carry out further analysis and statistical processing. Initially the user creates a reference to an emuDB by loading it into their current R session using the load_emuDB() function (see step 1). This database reference can then be used to either serve (serve()) the database to the EMU-webApp or query (query()) the annotations of the emuDB (see steps 2 and 3). The result of a query can then be used to either perform one or more so-called requeries or extract signal values that correspond to the result of a query() or requery() (see step 4). Finally, the signal data can undergo further preparation (e.g., correction of outliers) and visual inspection before further analysis and statistical processing is carried out (see steps 5, 6 and 7). Although the R packages provided by the EMU-SDMS do provide functions for steps 4, 5 and 6, it is worth noting that the plethora of R packages that the R package ecosystem provides can and should be used to perform these duties. The resulting objects of most of the above functions are derived matrix or data.frame objects which can be used as inputs for hundreds if not thousands of other R functions. 2.3 EMU-SDMS: Is it something for you? Besides providing a fully integrated system, the EMU-SDMS has several unique features that set it apart from other current, widely used systems (e.g., @boersma:2011a, @wittenburg:2006a, @fromont:2012a, @rose:2006a, @mcauliffe:2016a). To our knowledge, the EMU-SDMS is the only system that allows the user to model their annotation structures based on a hybrid model of time-based annotations (such as those offered by Praat’s tier-based annotation mechanics) and hierarchical timeless annotations. An example of such a hybrid annotation structure is displayed in Figure 2.2. These hybrid annotations benefit the user in multiple ways, as they reduce data redundancy and explicitly allow relationships to be expressed across annotation levels (see Chapter for further information on hierarchical annotations and Chapter on how to query these annotation structures). Figure 2.2: Example of a hybrid annotation combining time-based (Phonetic level) and hierarchical (Phoneme, Syllable, Text levels including the inter-level links) annotations. Further, to our knowledge, the EMU-SDMS is the first system that makes use of a web application as its primary GUI for annotating speech. This unique approach enables the GUI component to be used in multiple ways. It can be used as a stand-alone annotation tool, connected to a loaded emuDB via emuR’s serve() function and used to communicate to other servers. This enables it to be used as a collaborative annotation tool. An in-depth explanation of how this component can be used in these three scenarios is given in Chapter ??. As demonstrated in the default workflow of Section 2.2, an additional unique feature provided by EMU-SDMS is the ability to use the result of a query to extract derived (e.g., formants and RMS values) and complementary signals (e.g., electromagnetic articulography (EMA) data) that match the segments of a query. This, for example, aids the user in answering questions related to derived speech signals such as: Is the vowel height of the vowel @ (measured by its correlate, the first formant frequency) influenced by whether it appears in a strong or weak syllable?. Chapter gives a complete walk-through of how to go about answering this question using the tools provided by the EMU-SDMS. The features provided by the EMU-SDMS make it an all-in-one speech database management solution that is centered around R. It enriches the R platform by providing specialized speech signal processing, speech database management, data extraction and speech annotation capabilities. By achieving this without relying on any external software sources except the web browser, the EMU-SDMS significantly reduces the number of tools the speech and spoken language researcher has to deal with and helps to simplify answering research questions. As the only prerequisite for using the EMU-SDMS is a basic familiarity with the R platform, if the above features would improve your workflow, the EMU-SDMS is indeed for you. Sections of this chapter have been published in @winkelmann:2017aa↩ "],
["chap-tutorial.html", "3 A tutorial on how to use the EMU-SDMS 2 3.1 Converting the TextGrid collection 3.2 Loading and inspecting the database 3.3 Querying and autobuilding the annotation structure 3.4 Autobuilding 3.5 Signal extraction and exploration 3.6 Vowel height as a function of word types (content vs. function): evaluation and statistical analysis 3.7 Conclusion", " 3 A tutorial on how to use the EMU-SDMS 2 Using the tools provided by the EMU-SDMS, this tutorial chapter gives a practical step-by-step guide to answering the question: Given an annotated speech database, is the vowel height of the vowel @ (measured by its correlate, the first formant frequency) influenced by whether it appears in a content or function word? The tutorial only skims over many of the concepts and functions provided by the EMU-SDMS. In-depth explanations of the various functionalities are given in later chapters of this documentation. As the EMU-SDMS is not concerned with the raw data acquisition, other tools such as SpeechRecorder by @draxler:2004a are first used to record speech. However, once audio speech recordings are available, the system provides multiple conversion routines for converting existing collections of files to the new emuDB format described in Chapter ?? and importing them into the new EMU system. The current import routines provided by the emuR package are: convert_TextGridCollection() - Convert TextGrid collections (.wav and .TextGrid files) to the emuDB format, convert_BPFCollection() - Convert Bas Partitur Format (BPF) collections (.wav and .par files) to the emuDB format, convert_txtCollection() - Convert plain text file collections format (.wav and .txt files) to the emuDB format, convert_legacyEmuDB() - Convert the legacy EMU database format to the emuDB format and create_emuDB() followed by add_link/levelDefinition and import_mediaFiles() - Creating emuDBs from scratch with only audio files present. The emuR package comes with a set of example files and small databases that are used throughout the emuR documentation, including the functions help pages. These can be accessed by typing help(functionName) or the short form ?functionName. R Example ?? illustrates how to create this demo data in a user-specified directory. Throughout the examples of this documentation the directory that is provided by the base R function tempdir() will be used, as this is available on every platform supported by R (see ?tempdir for further details). As can be inferred from the list.dirs() output in R Example ??, the emuR_demoData directory contains a separate directory containing example data for each of the import routines. Additionally, it contains a directory containing an emuDB called ae (the directories name is ae_emuDB, where _emuDB is the default suffix given to directories containing a emuDB; see Chapter ??). rexample:tutorial-create-emuRdemoData # load the package library(emuR) # create demo data in directory provided by the tempdir() function # (of course other directory paths may be chosen) create_emuRdemoData(dir = tempdir()) # create path to demo data directory, which is # called &quot;emuR_demoData&quot; demoDataDir = file.path(tempdir(), &quot;emuR_demoData&quot;) # show demo data directories list.dirs(demoDataDir, recursive = F, full.names = F) ## [1] &quot;ae_emuDB&quot; &quot;BPF_collection&quot; &quot;legacy_ae&quot; ## [4] &quot;TextGrid_collection&quot; &quot;txt_collection&quot; This tutorial will start by converting a TextGrid collection containing seven annotated single-sentence utterances of a single male speaker to the emuDB format3. In the EMU-SDMS, a file collection such as a TextGrid collection refers to a set of file pairs where two types of files with different file extentions are present (e.g., .ext1 and .ext2). It is vital that file pairs have the same basenames (e.g., A.ext1 and A.ext2 where A represents the basename) in order for the conversion functions to be able to pair up files that belong together. As other speech software tools also encourage such file pairs (e.g., @kisler:2015a) this is a common collection format in the speech sciences. R Example shows such a file collection that is part of emuR’s demo data. Figure @ref(fig:msajc003_praatTG) shows the content of an annotation as displayed by Praat’s &quot;Draw visible sound and Textgrid...&quot; procedure. rexample:showTGcolContent # create path to TextGrid collection tgColDir = file.path(demoDataDir, &quot;TextGrid_collection&quot;) # show content of TextGrid_collection directory list.files(tgColDir) ## [1] &quot;msajc003.TextGrid&quot; &quot;msajc003.wav&quot; &quot;msajc010.TextGrid&quot; ## [4] &quot;msajc010.wav&quot; &quot;msajc012.TextGrid&quot; &quot;msajc012.wav&quot; ## [7] &quot;msajc015.TextGrid&quot; &quot;msajc015.wav&quot; &quot;msajc022.TextGrid&quot; ## [10] &quot;msajc022.wav&quot; &quot;msajc023.TextGrid&quot; &quot;msajc023.wav&quot; ## [13] &quot;msajc057.TextGrid&quot; &quot;msajc057.wav&quot; (#fig:msajc003_praatTG)TextGrid annotation of the emuR_demoData/TextGrid_collection/msajc003.wav / .TextGrid file pair containing the tiers (from top to bottom): Utterance, Intonational, Intermediate, Word, Accent, Text, Syllable, Phoneme, Phonetic, Tone, Foot. 3.1 Converting the TextGrid collection The convert_TextGridCollection() function converts a TextGrid collection to the emuDB format. A precondition that all .TextGrid files have to fulfill is that they must all contain the same tiers. If this is not the case, yet there is an equal tier subset that is contained in all the TextGrid files, this equal subset may be chosen. For example, if all .TextGrid files contain only the tier Phonetic: IntervalTier the conversion will work. However, if a single .TextGrid of the collection has the additional tier Tone: TextTier the conversion will fail. In this case the conversion could be made to work by specifying the equal subset (e.g., equalSubset = c(&quot;Phonetic&quot;)) and passing it on to the tierNames function argument convert_TextGridCollection(..., tierNames = equalSubset, ...). As can be seen in Figure ??, the TextGrid files provided by the demo data contain eleven tiers. To reduce the complexity of the annotations for this tutorial we will only convert the tiers Word (content: C vs. function: F word annotations), Syllable (strong: S vs. weak: W syllable annotations), Phoneme (phoneme level annotations) and Phonetic (phonetic annotations using Speech Assessment Methods Phonetic Alphabet (SAMPA) symbols - @wells:1997aa) using the tierNames parameter. This conversion can be seen in R Example @ref(rexample:tutorial_tgconv). rexample:tutorial_tgconv # convert TextGrid collection to the emuDB format convert_TextGridCollection(dir = tgColDir, dbName = &quot;myFirst&quot;, targetDir = tempdir(), tierNames = c(&quot;Word&quot;, &quot;Syllable&quot;, &quot;Phoneme&quot;, &quot;Phonetic&quot;)) The above call to convert_TextGridCollection() creates a new emuDB directory in the tempdir() directory called myFirst_emuDB. This emuDB contains annotation files that contain the same Word, Syllable, Phoneme and Phonetic segment tiers as the original .TextGrid files as well as copies of the original (.wav) audio files. For further details about the structure of an emuDB, see Chapter ?? of this document. 3.2 Loading and inspecting the database As mentioned in Section @ref(sec:overview_sysArch), the first step when working with an emuDB is to load it into the current R session. R Example ?? shows how to load the converted TextGrid collection into R using the load_emuDB() function. rexample:tutorial-loadEmuDB # get path to emuDB called &quot;myFirst&quot; # that was created by convert_TextGridCollection() path2directory = file.path(tempdir(), &quot;myFirst_emuDB&quot;) # load emuDB into current R session dbHandle = load_emuDB(path2directory, verbose = FALSE) 3.2.1 Overview Now the myFirst emuDB is loaded into R, an overview of the current status and configuration of the database can be displayed using the summary() function as shown in R Example @ref(rexample:tutorial_summary). rexample:tutorial_summary # show summary summary(dbHandle) ## Name: myFirst ## UUID: dbbba4c9-ca27-430c-ade1-5cfd0c914312 ## Directory: /private/var/folders/yk/8z9tn7kx6hbcg_9n4c1sld980000gn/T/RtmpoUPkbK/myFirst_emuDB ## Session count: 1 ## Bundle count: 7 ## Annotation item count: 664 ## Label count: 664 ## Link count: 0 ## ## Database configuration: ## ## SSFF track definitions: ## NULL ## ## Level definitions: ## name type nrOfAttrDefs attrDefNames ## 1 Word SEGMENT 1 Word; ## 2 Syllable SEGMENT 1 Syllable; ## 3 Phoneme SEGMENT 1 Phoneme; ## 4 Phonetic SEGMENT 1 Phonetic; ## ## Link definitions: ## NULL The extensive output of summary() is split into a top and bottom half, where the top half focuses on general information about the database (name, directory, annotation item count, etc.) and the bottom half displays information about the various SSFF track, level and link definitions of the emuDB. The summary information about the level definitions shows, for instance, that the myFirst database has a Word level of type SEGMENT and therefore contains annotation items that have a start time and a segment duration. It is worth noting that information about the SSFF track, level and link definitions corresponds to the output of the list_ssffTrackDefinitions(), list_levelDefinitions() and list\\_linkDefinitions() functions. 3.2.2 Database annotation and visual inspection The EMU-SDMS has a unique approach to annotating and visually inspecting databases, as it utilizes a web application called the EMU-webApp to act as its GUI. To be able to communicate with the web application the emuR package provides the serve() function which is used in R Example @ref(rexample:tutorial_serve). rexample:tutorial_serve # serve myFirst emuDB to the EMU-webApp serve(dbHandle) Executing this command will block the R console, automatically open up the system’s default browser and display the following message in the R console: ## Navigate your browser to the EMU-webApp URL: ## http://ips-lmu.github.io/EMU-webApp/ (should happen autom... ## Server connection URL: ## ws://localhost:17890 ## To stop the server press the &#39;clear&#39; button in the ## EMU-webApp or close/reload the webApp in your browser. The EMU-webApp, which is now connected to the database via the serve() function, can be used to visually inspect and annotate the emuDB. Figure 3.1 displays a screenshot of what the EMU-webApp looks like after automatically connecting to the server. As the EMU-webApp is a very feature-rich software annotation tool, this documentation has a whole chapter (see Chapter ??) on how to use it, what it is capable of and how to configure it. Further, the web application provides its own documentation which can be accessed by clicking the EMU icon in the top right hand corner of the application’s top menu bar. To close the connection and free up the blocked R console, simply click the clear button in the top menu bar of the EMU-webApp. Figure 3.1: Screenshot of EMU-webApp displaying msajc003 bundle of myFirst emuDB. 3.3 Querying and autobuilding the annotation structure An integral step in the default workflow of the EMU-SDMS is querying the annotations of a database. The emuR package implements a query() function to accomplish this task. This function evaluates an EMU Query Language (EQL) expression and extracts the annotation items from the database that match a query expression. As Chapter ?? gives a detailed description of the query mechanics provided by emuR, this tutorial will only use a very small, hopefully easy to understand subset of the EQL. The output of the summary() command in R Example @ref(rexample:tutorial_summary) and the screenshot in Figure 3.1 show that the myFirst emuDB contains four levels of annotations. R Example ?? shows four separate queries that query various segments on each of the available levels. The query expressions all use the matching operator == which returns annotation items whose labels match those specified to the right of the operator and that belong to the level specified to the left of the operator (i.e., LEVEL == LABEL; see Chapter ?? for a detailed description). rexample:tutorial-simpleQuery # query all segments containing the label # &quot;C&quot; (== content word) of the &quot;Word&quot; level sl_text = query(emuDBhandle = dbHandle, query = &quot;Word == C&quot;) # query all segments containing the label # &quot;S&quot; (== strong syllable) of the &quot;Syllable&quot; level sl_syl = query(emuDBhandle = dbHandle, query = &quot;Syllable == S&quot;) # query all segments containing the label # &quot;f&quot; on the &quot;Phoneme&quot; level sl_phoneme = query(dbHandle, query = &quot;Phoneme == f&quot;) # query all segments containing the label # &quot;n&quot; of the &quot;Phonetic&quot; level sl_phonetic = query(dbHandle, query = &quot;Phonetic == n&quot;) # show class vector of query result class(sl_phonetic) ## [1] &quot;emuRsegs&quot; &quot;emusegs&quot; &quot;data.frame&quot; # show first entry of sl_phonetic head(sl_phonetic, n = 1) ## segment list from database: myFirst ## query was: Phonetic == n ## labels start end session bundle level type ## 1 n 1031.925 1195.925 0000 msajc003 Phonetic SEGMENT # show summary of sl_phonetic summary(sl_phonetic) ## segment list from database: myFirst ## query was: Phonetic == n ## with 12 segments ## ## Segment distribution: ## ## n ## 12 As demonstrated in R Example @ref(rexample:tutorial_simpleQuery), the result of a query is an emuRsegs object, which is a super-class of the common data.frame. This object is often referred to as a segment list, or “seglist”. A segment list carries information about the extracted annotation items such as the extracted labels, the start and end times of the segments, the sessions and bundles the items are from and the levels they belong to. An in-depth description of the information contained in a segment list is given in Section ??. R Example @ref(rexample:tutorial_simpleQuery) shows that the summary() function can also be applied to a segment list object to get an overview of what is contained within it. This can be especially useful when dealing with larger segment lists. 3.4 Autobuilding The simple queries illustrated above query segments from a single level that match a certain label. However, the EMU-SDMS offers a mechanism for performing inter-level queries such as: Query all Phonetic items that contain the label “n” and are part of a content word. For such queries to be possible, the EMU-SDMS offers very sophisticated annotation structure modeling capabilities, which are described in Chapter ??. For the sake of this tutorial we will focus on converting the flat segment level annotation structure displayed in Figure 3.1 to a hierarchical form as displayed in Figure 3.2, where only the Phonetic level carries time information and the annotation items on the other levels are explicitly linked to each other to form a hierarchical annotation structure. Figure 3.2: Example of a hierarchical annotation of the content (==C) word violently belonging to the msajc012 bundle of the myFirst demo emuDB. As it is a very laborious task to manually link annotation items together using the EMU-webApp and the hierarchical information is already implicitly contained in the time information of the segments and events of each level, we will now use a function provided by the emuR package to build these hierarchical structures using this information called autobuild_linkFromTimes(). R Example ?? shows the calls to this function which autobuild the hierarchical annotations in the myFirst database. As a general rule for autobuilding hierarchical annotation structures, a good strategy is to start the autobuilding process beginning with coarser grained annotation levels (i.e., the Word/Syllable level pair in our example) and work down to finer grained annotations (i.e., the Syllable/Phoneme and Phoneme/Phonetic} level pairs in our example). To build hierachical annotation structures we need link definitions, which together with the level definitions define the annotation structure for the entire database (see Chapter ?? for further details). The autobuild_linkFromTimes() calls in R Example ?? use the newLinkDefType parameter, which if defined automatically adds a link definition to the database. rexample:tutorial-autobuild # invoke autobuild function # for &quot;Word&quot; and &quot;Syllable&quot; levels autobuild_linkFromTimes(dbHandle, superlevelName = &quot;Word&quot;, sublevelName = &quot;Syllable&quot;, convertSuperlevel = TRUE, newLinkDefType = &quot;ONE_TO_MANY&quot;) # invoke autobuild function # for &quot;Syllable&quot; and &quot;Phoneme&quot; levels autobuild_linkFromTimes(dbHandle, superlevelName = &quot;Syllable&quot;, sublevelName = &quot;Phoneme&quot;, convertSuperlevel = TRUE, newLinkDefType = &quot;ONE_TO_MANY&quot;) # invoke autobuild function # for &quot;Phoneme&quot; and &quot;Phonetic&quot; levels autobuild_linkFromTimes(dbHandle, superlevelName = &quot;Phoneme&quot;, sublevelName = &quot;Phonetic&quot;, convertSuperlevel = TRUE, newLinkDefType = &quot;MANY_TO_MANY&quot;) Figure 3.3: Schematic annotation structure of the emuDB after calling the autobuild function in R Example @ref(rexample:tutorial-autobuild). As the autobuild_linkFromTimes() function automatically creates backup levels to avoid the accidental loss of boundary or event time information, R Example @ref(rexample:tutorial_delBackupLevels) shows how these backup levels can be removed to clean up the database. However, using the remove_levelDefinition() function with its force parameter set to TRUE is a very invasive action. Usually this would not be recommended, but for this tutorial we are keeping everything as clean as possible. rexample:tutorial-delBackupLevels # list level definitions # as this reveals the &quot;-autobuildBackup&quot; levels # added by the autobuild_linkFromTimes() calls list_levelDefinitions(dbHandle) ## name type nrOfAttrDefs attrDefNames ## 1 Word ITEM 1 Word; ## 2 Syllable ITEM 1 Syllable; ## 3 Phoneme ITEM 1 Phoneme; ## 4 Phonetic SEGMENT 1 Phonetic; ## 5 Word-autobuildBackup SEGMENT 1 Word-autobuildBackup; ## 6 Syllable-autobuildBackup SEGMENT 1 Syllable-autobuildBackup; ## 7 Phoneme-autobuildBackup SEGMENT 1 Phoneme-autobuildBackup; # remove the levels containing the &quot;-autobuildBackup&quot; # suffix remove_levelDefinition(dbHandle, name = &quot;Word-autobuildBackup&quot;, force = TRUE, verbose = FALSE) remove_levelDefinition(dbHandle, name = &quot;Syllable-autobuildBackup&quot;, force = TRUE, verbose = FALSE) remove_levelDefinition(dbHandle, name = &quot;Phoneme-autobuildBackup&quot;, force = TRUE, verbose = FALSE) # list level definitions list_levelDefinitions(dbHandle) ## name type nrOfAttrDefs attrDefNames ## 1 Word ITEM 1 Word; ## 2 Syllable ITEM 1 Syllable; ## 3 Phoneme ITEM 1 Phoneme; ## 4 Phonetic SEGMENT 1 Phonetic; # list level definitions # which were added by the autobuild functions list_linkDefinitions(dbHandle) ## type superlevelName sublevelName ## 1 ONE_TO_MANY Word Syllable ## 2 ONE_TO_MANY Syllable Phoneme ## 3 MANY_TO_MANY Phoneme Phonetic As can be seen by the output of list_levelDefinitions() and list_linkDefinitions() in R Example ??, the annotation structure of the myFirst emuDB now matches that displayed in Figure @ref(fig:tutorial_simpleAnnotStruct). Using the serve() function to open the emuDB in the EMU-webApp followed by clicking on the show hierarchy button in the top menu (and rotating the hierarchy by 90 degrees by clicking the rotate by 90 degrees button) will result in a view similar to the screenshot of Figure ??. Figure 3.4: Screenshot of EMU-webApp displaying the autobuilt hierarchy of the myFirst emuDB. 3.4.1 Querying the hierarchical annotations Having this hierarchical annotation structure now allows us to formulate a query that helps answer the originally stated question: Given an annotated speech database, is the vowel height of the vowel @ (measured by its correlate, the first formant frequency) influenced by whether it appears in a content or function word?. R Example shows how all the @* vowels in the myFirst* database are queried. rexample:tutorial-labelGroupQuery # query annotation items containing # the labels @ on the Phonetic level sl_vowels = query(dbHandle, &quot;Phonetic == @&quot;) # show first entry of sl_vowels head(sl_vowels, n = 1) ## segment list from database: myFirst ## query was: Phonetic == @ ## labels start end session bundle level type ## 1 @ 1506.175 1548.425 0000 msajc003 Phonetic SEGMENT As the type of word (content vs. function) for each @* vowel that was just extracted is also needed, we can use the requery functionality of the EMU-SDMS (see Chapter ??) to retrieve the word type for each @* vowel. A requery essentially moves through a hierarchical annotation (vertically or horizontally) starting from the segments that are passed into the requery function. R Example ?? illustrates the usage of the hierarchical requery function, requery_hier(), to retrieve the appropriate annotation items from the *Word level. rexample:tutorial-requery # hierarchical requery starting from the items in sl_vowels # and moving up to the &quot;Word&quot; level sl_wordType = requery_hier(dbHandle, seglist = sl_vowels, level = &quot;Word&quot;, calcTimes = FALSE) # show first entry of sl_wordType head(sl_wordType, n = 1) ## segment list from database: myFirst ## query was: FROM REQUERY ## labels start end session bundle level type ## 1 F NA NA 0000 msajc003 Word ITEM # show that sl_vowel and sl_wordType have the # same number of row entries nrow(sl_vowels) == nrow(sl_wordType) ## [1] TRUE As can be seen by the nrow() comparison in R Example ??, the segment list returned by the requery_hier() function has the same number of rows as the original sl_vowels segment list. This is important, as each row of both segment lists line up and allow us to infer which segment belongs to which word type (e.g., vowel sl_vowels[5,] belongs to the word type sl_wordType[5,]). 3.5 Signal extraction and exploration Now that the vowel and word type information including the vowel start and end time information has been extracted from the database, this information can be used to extract signal data that matches these segments. Using the emuR function get_trackdata() we can calculate the formant values in real time using the formant estimation function, forest(), provided by the wrassp package (see Chapter ?? for details). R Example ?? shows the usage of this function. rexample:tutorial-getTrackdata # get formant values for the vowel segments td_vowels = get_trackdata(dbHandle, seglist = sl_vowels, onTheFlyFunctionName = &quot;forest&quot;, verbose = F) # show class vector class(td_vowels) ## [1] &quot;trackdata&quot; # show dimensions dim(td_vowels) ## [1] 28 4 # display all values for fifth segment td_vowels[5,] ## trackdata from track: fm ## index: ## left right ## 1 12 ## ftime: ## start end ## [1,] 2447.5 2502.5 ## data: ## T1 T2 T3 T4 ## 2447.5 303 1031 2266 3366 ## 2452.5 289 967 2250 3413 ## 2457.5 296 905 2273 3503 ## 2462.5 321 885 2357 3506 ## 2467.5 316 889 2397 3475 ## 2472.5 306 863 2348 3548 ## 2477.5 314 832 2339 3611 ## 2482.5 325 795 2342 3622 ## 2487.5 339 760 2322 3681 ## 2492.5 335 746 2316 3665 ## 2497.5 341 734 2306 3688 ## 2502.5 361 733 2304 3692 As can be seen by the call to the class() function, the resulting object is of the type trackdata and has 28 entries. This corresponds to the number of rows contained in the segment lists extracted above (i.e., nrow(sl_vowels)). This indicates that this object contains data for each of the segments that correspond to each of the row entries of the segment lists (i.e., td_vowels[5,] are the formant values belonging to sl_vowels[5,]). As the columns T1, T2, T3, T4 of the printed output of td_vowels[5,] suggest, the forest function estimates four formant values. We will only be concerned with the first (column T1) and second (column T2). R Example ?? shows a call to emuR’s dplot() function which produces the plot displayed in Figure 3.5. The first call to the dplot() function plots all 28 first formant trajectories (achieved by indexing the first column i.e., T1: x = td_vowels[, 1]). To clean up the cluttered left plot, the second call to the dplot() function additionally uses the average parameter to plot only the ensemble averages of all *@* vowels and time-normalizes the trajectories (normalise = TRUE) to an interval between 0 and 1. rexample:tutorial-dplot # two plots next to each other formantNr = 1 par(mfrow = c(1,2)) dplot(x = td_vowels[, formantNr], labs = sl_vowels$labels, xlab = &quot;Duration (ms)&quot;, ylab = paste0(&quot;F&quot;, formantNr, &quot; (Hz)&quot;)) dplot(x = td_vowels[, 1], labs = sl_vowels$labels, normalise = TRUE, average = TRUE, xlab = &quot;Normalized time&quot;, ylab = paste0(&quot;F&quot;, formantNr, &quot; (Hz)&quot;)) # back to single plot par(mfrow = c(1,1)) Figure 3.5: dplot() plots of F1 trajectories. The left plot displays all trajectories while the right plot displays the ensemble average of all *@* vowels. Figure 3.5 gives an overview of the first formant trajectories of the *@* vowels. For the purpose of data exploration and to get an idea of where the individual vowel classes lie on the F2 x F1 plane, which indirectly provides information about vowel height and tongue position, R Example ?? makes use of the eplot() function. This produces Figure 3.6. To be able to use the eplot() function, the td_vowels object first has to be modified, as it contains entire formant trajectories but two dimensional data is needed to be able to display it on the F2 x F1 plain. This can, for example, be achieved by only extracting temporal mid-point formant values for each vowel using the get_trackdata() function utilizing its cut parameter. R Example ?? shows an alternative approach using the dcut() function to essentially cut the formant trajectories to a specified proportional segment. By using only the left.time = 0.5 (and not specifying right.time) only the formant values that are closest to the temporal mid-point are cut from the trajectories. rexample:tutorial-eplot # cut formant trajectories at temporal mid-point td_vowels_midpoint = dcut(td_vowels, left.time = 0.5, prop = TRUE) # show dimensions of td_vowels_midpoint dim(td_vowels_midpoint) # generate plot eplot(x = td_vowels_midpoint[,1:2], labs = sl_vowels$labels, dopoints = TRUE, formant = TRUE, xlab=&quot;F2 (Hz)&quot;, ylab = &quot;F1 (Hz)&quot; ) Figure 3.6: 95% ellipses for F2 x F1 data extracted from the temporal midpoint of the vowel segments. Figure @ref{fig:tutorial-eplot} displays the first two formants extracted at the temporal midpoint of every *@* vowel in sl_vowels. These formants are plotted on the F2 x F1 plane, and their 95% ellipsis distribution is also shown. Although not necessarily applicable to the question posed at the beginning of this tutorial, the data exploration using the dplot() and eplot() functions can be very helpful tools for providing an overview of the data at hand. 3.6 Vowel height as a function of word types (content vs. function): evaluation and statistical analysis The above data exploration only dealt with the actual @* vowels and disregarded the syllable type they occurred in. However, the question in the introduction of this chapter focuses on whether the @* vowel occurs in a content (labeled C) or function (labeled F) word. For data inspection purposes, R Example ?? initially extracts the central 60% (left.time = 0.2 and right.time = 0.8) of the formant trajectories from td_vowels using dcut() and displays them using dplot(). It should be noted that the call to dplot() uses the labels of the sl_wordType object as opposed to those of sl_vowels. This causes the dplot() functions to group the trajectories by their word type as opposed to their vowel labels as displayed in Figure @ref(fig:tutorial_dplotSylTyp). rexample:tutorial-dplotSylTyp # extract central 60% from formant trajectories td_vowelsMidSec = dcut(td_vowels, left.time = 0.2, right.time = 0.8, prop = TRUE) # plot first formant trajectories formantNr = 1 dplot(x = td_vowelsMidSec[, formantNr], labs = sl_wordType$labels, normalise = TRUE, average = TRUE, xlab = &quot;Normalized time&quot;, ylab = paste(&quot;F&quot;, formantNr, &quot; (Hz)&quot;)) Figure 3.7: Ensemble averages of F1 contours of all tokens of the central 60% of vowels grouped by word type (function (F) vs. content (W)). As can be seen in Figure 3.7, there seems to be a distinction in F1 trajectory height between vowels in content and function words. R Example ?? shows the code to produce a boxplot using the ggplot2 package to further visually inspect the data (see Figure 3.8 for the plot produced by R Example @ref{rexample:tutorial-boxplot}). rexample:tutorial-boxplot formantNr = 1 # use trapply to calculate the means of the 60% # formant trajectories td_vowelsMidSec_mean = trapply(td_vowelsMidSec[, formantNr], fun = mean, simplify = T) # create new data frame that contains the mean # values and the corresponding labels df = data.frame(wordType = sl_wordType$labels, meanF1 = td_vowelsMidSec_mean) # load library library(ggplot2) # create boxplot using ggplot ggplot(df, aes(wordType, meanF1)) + geom_boxplot() + labs(x = &quot;Word type&quot;, y = paste0(&quot;mean F&quot;, formantNr, &quot; (Hz)&quot;)) Figure 3.8: Boxplot produced using ggplot2 to visualize the difference in F1 depending on whether the vowel occurs in content (C) or function (F) word. To confirm or reject this, R Example ?? presents a very simple statistical analysis of the F1 mean values of the 60% mid-section formant trajectories 4. First, a Shapiro-Wilk test for normality of the distributions of the F1 means for both word types is carried out. As only one type is normally distributed, a Wilcoxon rank sum test is performed. The density distributions (commented out plot() function calls in R Example ??) are displayed in Figure @ref(fig:tutorial_stats1). rexample:tutorial-stats1 # calculate density for vowels in function words distrF = density(df[df$wordType == &quot;F&quot;,]$meanF1) # uncomment to visualize distribution # plot(distrF) # check that vowels in function # words are normally distributed shapiro.test(df[df$wordType == &quot;F&quot;,]$meanF1) ## ## Shapiro-Wilk normality test ## ## data: df[df$wordType == &quot;F&quot;, ]$meanF1 ## W = 0.98687, p-value = 0.9887 # p-value &gt; 0.05 implying that the distribution # of the data ARE NOT significantly different from # normal distribution -&gt; we CAN assume normality # calculate density for vowels in content words distrC = density(df[df$wordType == &quot;C&quot;,]$meanF1) # uncomment to visualize distribution # plot(distrC) # check that vowels in content # words are normally distributed: shapiro.test(df[df$wordType == &quot;C&quot;,]$meanF1) ## ## Shapiro-Wilk normality test ## ## data: df[df$wordType == &quot;C&quot;, ]$meanF1 ## W = 0.66506, p-value = 1.506e-05 # p-value &lt; 0.05 implying that the distribution # of the data ARE significantly different from # normal distribution -&gt; we CAN NOT assume normality # (this somewhat unexpected result is probably # due to the small sample size used in this toy example) # -&gt; use Wilcoxon rank sum test # perform Wilcoxon rank sum test to establish # whether vowel F1 depends on word type wilcox.test(meanF1 ~ wordType, data = df) ## ## Wilcoxon rank sum test ## ## data: meanF1 by wordType ## W = 121, p-value = 0.03752 ## alternative hypothesis: true location shift is not equal to 0 Figure 3.9: Plots of density distributions of vowels in content words (left plot) and vowels in function words (right plot) in R Example @ref(rexample:tutorial_stats1). As shown by the result of wilcox.test() in R Example @ref(rexample:tutorial_stats1), word type (C vs. F) has a significant influence on the vowel’s F1 (W=121, p&lt;0.05). Hence, the answer to the initially proposed question: Given an annotated speech database, is vowel height of the vowel @ (measured by its correlate, the first formant frequency) influenced by whether it appears in a content or function word? is yes! 3.7 Conclusion The tutorial given in this chapter gave an overview of what it is like working with the EMU-SDMS to try to solve a research question. As many of the concepts were only briefly explained, it is worth noting that explicit explanations of the various components and integral concepts are given in following chapters. Further, additional use cases that have been taken from the emuR_intro vignette can be found in Appendix @ref(app_chap:useCases). These use cases act as templates for various types of research questions and will hopefully aid the user in finding a solution similar to what she or he wishes to achieve. Some examples of this chapter are adapted versions of examples of the emuR_intro vignette.↩ The other input routines are covered in the Section @ref(sec:emuRpackageDetails_importRoutines).↩ It is worth noting that the sample size in this toy example is quite small. This obviously influences the outcome of the simple statistical analysis that is performed here.↩ "]
]
